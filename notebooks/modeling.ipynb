{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.ipynb\n",
    "\n",
    "This notebook will handle modeling and data preprocessing for our problem.\n",
    "\n",
    "Evaluation Metrics:\n",
    "- Brier Score (this is the main one)\n",
    "- Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import brier_score_loss, accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>lower_TeamID</th>\n",
       "      <th>lower_Wins</th>\n",
       "      <th>lower_Losses</th>\n",
       "      <th>lower_Winning Percentage</th>\n",
       "      <th>lower_Score_mean</th>\n",
       "      <th>lower_FGM_mean</th>\n",
       "      <th>lower_FGA_mean</th>\n",
       "      <th>lower_FGM3_mean</th>\n",
       "      <th>lower_FGA3_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>higher_AssistToTurnoverRatio_std</th>\n",
       "      <th>higher_Possessions_std</th>\n",
       "      <th>higher_OffEff_std</th>\n",
       "      <th>higher_DefEff_std</th>\n",
       "      <th>higher_TO%_std</th>\n",
       "      <th>higher_PointDiff_std</th>\n",
       "      <th>higher_OffensiveRating_std</th>\n",
       "      <th>higher_DefensiveRating_std</th>\n",
       "      <th>Bracket</th>\n",
       "      <th>LowerWin?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>2019</td>\n",
       "      <td>1242</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>75.382353</td>\n",
       "      <td>27.294118</td>\n",
       "      <td>59.058824</td>\n",
       "      <td>7.235294</td>\n",
       "      <td>20.647059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881175</td>\n",
       "      <td>7.485740</td>\n",
       "      <td>25.135399</td>\n",
       "      <td>45.694237</td>\n",
       "      <td>0.139550</td>\n",
       "      <td>12.276641</td>\n",
       "      <td>62672.908339</td>\n",
       "      <td>241.659481</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2009</td>\n",
       "      <td>1143</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>75.031250</td>\n",
       "      <td>27.093750</td>\n",
       "      <td>55.906250</td>\n",
       "      <td>6.343750</td>\n",
       "      <td>14.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483462</td>\n",
       "      <td>5.707081</td>\n",
       "      <td>24.857249</td>\n",
       "      <td>37.922101</td>\n",
       "      <td>0.101832</td>\n",
       "      <td>17.022045</td>\n",
       "      <td>56403.384404</td>\n",
       "      <td>586.620957</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>2010</td>\n",
       "      <td>1352</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>23.323529</td>\n",
       "      <td>53.323529</td>\n",
       "      <td>5.647059</td>\n",
       "      <td>15.470588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435349</td>\n",
       "      <td>5.966921</td>\n",
       "      <td>31.325718</td>\n",
       "      <td>35.567874</td>\n",
       "      <td>0.129745</td>\n",
       "      <td>14.418477</td>\n",
       "      <td>66317.665445</td>\n",
       "      <td>600.246113</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>2011</td>\n",
       "      <td>1242</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>82.382353</td>\n",
       "      <td>29.588235</td>\n",
       "      <td>57.617647</td>\n",
       "      <td>7.264706</td>\n",
       "      <td>18.764706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.540804</td>\n",
       "      <td>7.140057</td>\n",
       "      <td>34.335500</td>\n",
       "      <td>38.461804</td>\n",
       "      <td>0.152372</td>\n",
       "      <td>10.118593</td>\n",
       "      <td>49478.637137</td>\n",
       "      <td>459.165885</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>2011</td>\n",
       "      <td>1228</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>71.281250</td>\n",
       "      <td>26.343750</td>\n",
       "      <td>56.343750</td>\n",
       "      <td>6.843750</td>\n",
       "      <td>17.687500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637593</td>\n",
       "      <td>7.101537</td>\n",
       "      <td>35.161898</td>\n",
       "      <td>40.164503</td>\n",
       "      <td>0.164143</td>\n",
       "      <td>15.802057</td>\n",
       "      <td>79118.599885</td>\n",
       "      <td>797.290386</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season  lower_TeamID  lower_Wins  lower_Losses  \\\n",
       "1057    2019          1242          25             9   \n",
       "389     2009          1143          22            10   \n",
       "462     2010          1352          23            11   \n",
       "575     2011          1242          32             2   \n",
       "559     2011          1228          19            13   \n",
       "\n",
       "      lower_Winning Percentage  lower_Score_mean  lower_FGM_mean  \\\n",
       "1057                  0.735294         75.382353       27.294118   \n",
       "389                   0.687500         75.031250       27.093750   \n",
       "462                   0.676471         68.500000       23.323529   \n",
       "575                   0.941176         82.382353       29.588235   \n",
       "559                   0.593750         71.281250       26.343750   \n",
       "\n",
       "      lower_FGA_mean  lower_FGM3_mean  lower_FGA3_mean  ...  \\\n",
       "1057       59.058824         7.235294        20.647059  ...   \n",
       "389        55.906250         6.343750        14.625000  ...   \n",
       "462        53.323529         5.647059        15.470588  ...   \n",
       "575        57.617647         7.264706        18.764706  ...   \n",
       "559        56.343750         6.843750        17.687500  ...   \n",
       "\n",
       "      higher_AssistToTurnoverRatio_std  higher_Possessions_std  \\\n",
       "1057                          0.881175                7.485740   \n",
       "389                           0.483462                5.707081   \n",
       "462                           0.435349                5.966921   \n",
       "575                           0.540804                7.140057   \n",
       "559                           0.637593                7.101537   \n",
       "\n",
       "      higher_OffEff_std  higher_DefEff_std  higher_TO%_std  \\\n",
       "1057          25.135399          45.694237        0.139550   \n",
       "389           24.857249          37.922101        0.101832   \n",
       "462           31.325718          35.567874        0.129745   \n",
       "575           34.335500          38.461804        0.152372   \n",
       "559           35.161898          40.164503        0.164143   \n",
       "\n",
       "      higher_PointDiff_std  higher_OffensiveRating_std  \\\n",
       "1057             12.276641                62672.908339   \n",
       "389              17.022045                56403.384404   \n",
       "462              14.418477                66317.665445   \n",
       "575              10.118593                49478.637137   \n",
       "559              15.802057                79118.599885   \n",
       "\n",
       "      higher_DefensiveRating_std  Bracket  LowerWin?  \n",
       "1057                  241.659481        M          1  \n",
       "389                   586.620957        M          0  \n",
       "462                   600.246113        M          0  \n",
       "575                   459.165885        M          0  \n",
       "559                   797.290386        M          0  \n",
       "\n",
       "[5 rows x 191 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the training data\n",
    "training_data = pd.read_csv('/Users/jinalshah/Jinal/Projects/march-madness-mania/preprocessed-data/modeling-data/training.csv',index_col=0)\n",
    "\n",
    "# Making sure the data loaded correctly\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to make sure there aren't any missing values\n",
    "missing_vals = dict(training_data.isna().sum())\n",
    "\n",
    "# Iterating through the dictionary\n",
    "for col in missing_vals.keys():\n",
    "    if missing_vals[col] > 0:\n",
    "        print(f'Column {col} has {missing_vals[col]} missing values')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We need to preprocess the data a little bit so let's do that!\n",
    "\n",
    "Preprocessing that needs to be done:\n",
    "- Dropping the identifiers (lower_TeamID,higher_TeamID)\n",
    "- Converting Season into a number for how many seasons back the data is from (-1 = last season, -2 = 2 seasons ago, etc)\n",
    "- Converting Bracket into dummy variables\n",
    "- Scaling all numerical values by z-score to gain a normal distribution and all numbers on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of the training set \n",
    "training_data_preprocessed = training_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the unnecessary features\n",
    "training_data_preprocessed.drop(['lower_TeamID','higher_TeamID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Season into numbers\n",
    "training_data_preprocessed['Season_converted'] = training_data_preprocessed['Season'] - 2023.0\n",
    "training_data_preprocessed.drop(['Season'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features matrix and target\n",
    "features = training_data_preprocessed.drop(['LowerWin?'],axis=1)\n",
    "target = training_data_preprocessed['LowerWin?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into numerical and categorical\n",
    "categorical = ['Bracket']\n",
    "numerical = list(features.columns)\n",
    "numerical.remove('Bracket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a pipeline to perform all the appropriate transformations\n",
    "preprocessing_pipeline = ColumnTransformer(transformers=[\n",
    "    ('scaler',StandardScaler(with_mean=True,with_std=True),numerical),\n",
    "    ('encoder',OneHotEncoder(),categorical)\n",
    "],remainder='passthrough',n_jobs=-1,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ColumnTransformer] ....... (2 of 2) Processing encoder, total=   0.0s\n",
      "[ColumnTransformer] ........ (1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.23655977,  0.5006731 , -0.28877454, ...,  1.03353159,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.49451463,  0.78784489, -0.72021046, ..., -0.86041151,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.25082316,  1.07501668, -0.8197726 , ..., -0.6710172 ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.72394271, -0.93518583,  0.93594679, ..., -0.6710172 ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.96763417, -0.93518583,  0.97234585, ...,  1.03353159,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.96763417, -0.93518583,  0.97234585, ..., -0.48162289,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming the feature matrix via the pipeline\n",
    "features_preprocessed = preprocessing_pipeline.fit_transform(features)\n",
    "\n",
    "# Making sure fitting happened properly\n",
    "features_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is preprocessed!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Now that we have preprocessed the data for our models, it is time to build our models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary that holds various metrics\n",
    "metrics = {'Model':[],'Brier Score Training':[],'Mean Brier Score CV':[], 'Accuracy Training':[],'Mean Accuracy CV':[]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier\n",
    "\n",
    "This is our baseline. This classifier will simply randomly choose a class based on a uniform distribution of the class (0 or 1).\n",
    "We want our models to ideally be much better than this classifier, hence this is what we compare to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(random_state=42, strategy=&#x27;uniform&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(random_state=42, strategy=&#x27;uniform&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(random_state=42, strategy='uniform')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the dummy classifier\n",
    "dummy_classifier = DummyClassifier(strategy='uniform',random_state=42)\n",
    "dummy_classifier.fit(features_preprocessed,target) # Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting training scores\n",
    "train_pred = dummy_classifier.predict(features_preprocessed)\n",
    "train_probs = dummy_classifier.predict_proba(features_preprocessed)[:,1]\n",
    "\n",
    "# Getting the metrics\n",
    "train_brier = brier_score_loss(target,train_probs)\n",
    "train_accuracy = accuracy_score(target,train_pred)\n",
    "\n",
    "# Adding metrics to the dictionary\n",
    "model_list = metrics['Model']\n",
    "model_list.append('Dummy Classifier')\n",
    "metrics['Model'] = model_list\n",
    "train_briers = metrics['Brier Score Training']\n",
    "train_briers.append(train_brier)\n",
    "metrics['Brier Score Training'] = train_briers\n",
    "train_accuracies = metrics['Accuracy Training']\n",
    "train_accuracies.append(train_accuracy)\n",
    "metrics['Accuracy Training'] = train_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the results and adding it to the dictionary\n",
    "results = cross_validate(dummy_classifier,features_preprocessed,target,scoring=['accuracy','neg_brier_score'],\n",
    "                         cv=5,n_jobs=-1)\n",
    "\n",
    "cv_briers = metrics['Mean Brier Score CV']\n",
    "cv_briers.append((-1*results['test_neg_brier_score']).mean())\n",
    "metrics['Mean Brier Score CV'] = cv_briers\n",
    "cv_accuracies = metrics['Mean Accuracy CV']\n",
    "cv_accuracies.append((results['test_accuracy']).mean())\n",
    "metrics['Mean Accuracy CV'] = cv_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model in a pickle file\n",
    "pickle.dump(dummy_classifier,open('/Users/jinalshah/Jinal/Projects/march-madness-mania/models/dummy_classifier.sav','wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logisitic Regression\n",
    "\n",
    "I am going to try a logisitic regression model. I don't expect this model to do too well since the I don't expect linear classification to be the answer to this problem. However, I do want to see how a non-regularized logistic regression model does. Expectation is that this model performs better than the dummy classifier by a significant margin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, n_jobs=-1, penalty=None, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, n_jobs=-1, penalty=None, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, n_jobs=-1, penalty=None, random_state=42)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model\n",
    "logistic_reg = LogisticRegression(penalty=None,C=1.0,random_state=42,max_iter=1000,n_jobs=-1)\n",
    "logistic_reg.fit(features_preprocessed,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting training scores\n",
    "train_pred = logistic_reg.predict(features_preprocessed)\n",
    "train_probs = logistic_reg.predict_proba(features_preprocessed)[:,1]\n",
    "\n",
    "# Getting the metrics\n",
    "train_brier = brier_score_loss(target,train_probs)\n",
    "train_accuracy = accuracy_score(target,train_pred)\n",
    "\n",
    "# Adding metrics to the dictionary\n",
    "model_list = metrics['Model']\n",
    "model_list.append('Logistic Regression - No Regularization')\n",
    "metrics['Model'] = model_list\n",
    "train_briers = metrics['Brier Score Training']\n",
    "train_briers.append(train_brier)\n",
    "metrics['Brier Score Training'] = train_briers\n",
    "train_accuracies = metrics['Accuracy Training']\n",
    "train_accuracies.append(train_accuracy)\n",
    "metrics['Accuracy Training'] = train_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the results and adding it to the dictionary\n",
    "results = cross_validate(logistic_reg,features_preprocessed,target,scoring=['accuracy','neg_brier_score'],\n",
    "                         cv=5,n_jobs=-1)\n",
    "\n",
    "cv_briers = metrics['Mean Brier Score CV']\n",
    "cv_briers.append((-1*results['test_neg_brier_score']).mean())\n",
    "metrics['Mean Brier Score CV'] = cv_briers\n",
    "cv_accuracies = metrics['Mean Accuracy CV']\n",
    "cv_accuracies.append((results['test_accuracy']).mean())\n",
    "metrics['Mean Accuracy CV'] = cv_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model in a pickle file\n",
    "pickle.dump(logistic_reg,open('/Users/jinalshah/Jinal/Projects/march-madness-mania/models/logistic_reg_unregularized.sav','wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "Logistic Regression (Un-Regularized) did better than the dummy classifier. However, it did overfit a lot (which was expected) causing the CV Brier to not improve as much. Decision Trees are a much better model! I do expect overfitting; however, it will still lower the Mean Brier Score CV by a lot, I hope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {color: black;background-color: white;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model\n",
    "decision_tree = DecisionTreeClassifier(criterion='gini',random_state=42)\n",
    "decision_tree.fit(features_preprocessed,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting training scores\n",
    "train_pred = decision_tree.predict(features_preprocessed)\n",
    "train_probs = decision_tree.predict_proba(features_preprocessed)[:,1]\n",
    "\n",
    "# Getting the metrics\n",
    "train_brier = brier_score_loss(target,train_probs)\n",
    "train_accuracy = accuracy_score(target,train_pred)\n",
    "\n",
    "# Adding metrics to the dictionary\n",
    "model_list = metrics['Model']\n",
    "model_list.append('Decision Tree - UnRegularized')\n",
    "metrics['Model'] = model_list\n",
    "train_briers = metrics['Brier Score Training']\n",
    "train_briers.append(train_brier)\n",
    "metrics['Brier Score Training'] = train_briers\n",
    "train_accuracies = metrics['Accuracy Training']\n",
    "train_accuracies.append(train_accuracy)\n",
    "metrics['Accuracy Training'] = train_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the results and adding it to the dictionary\n",
    "results = cross_validate(decision_tree,features_preprocessed,target,scoring=['accuracy','neg_brier_score'],\n",
    "                         cv=5,n_jobs=-1)\n",
    "\n",
    "cv_briers = metrics['Mean Brier Score CV']\n",
    "cv_briers.append((-1*results['test_neg_brier_score']).mean())\n",
    "metrics['Mean Brier Score CV'] = cv_briers\n",
    "cv_accuracies = metrics['Mean Accuracy CV']\n",
    "cv_accuracies.append((results['test_accuracy']).mean())\n",
    "metrics['Mean Accuracy CV'] = cv_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model in a pickle file\n",
    "pickle.dump(decision_tree,open('/Users/jinalshah/Jinal/Projects/march-madness-mania/models/decision_tree_unregularized.sav','wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Very interesting! Decision Trees overfit so bad that it performed worse or just marginally better than the dummy classifier. It did excellent on the training set but did so bad on the validation set. \n",
    "\n",
    "Let's see how Random Forests do; however, I expect them to do just as bad since its just a bagging of decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {color: black;background-color: white;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_samples=0.7, n_estimators=1000, n_jobs=-1,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_samples=0.7, n_estimators=1000, n_jobs=-1,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_samples=0.7, n_estimators=1000, n_jobs=-1,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model\n",
    "random_forest = RandomForestClassifier(n_estimators=1000,criterion='gini',bootstrap=True,n_jobs=-1,random_state=42,max_samples=0.7)\n",
    "random_forest.fit(features_preprocessed,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting training scores\n",
    "train_pred = random_forest.predict(features_preprocessed)\n",
    "train_probs = random_forest.predict_proba(features_preprocessed)[:,1]\n",
    "\n",
    "# Getting the metrics\n",
    "train_brier = brier_score_loss(target,train_probs)\n",
    "train_accuracy = accuracy_score(target,train_pred)\n",
    "\n",
    "# Adding metrics to the dictionary\n",
    "model_list = metrics['Model']\n",
    "model_list.append('Random Forest - Basic')\n",
    "metrics['Model'] = model_list\n",
    "train_briers = metrics['Brier Score Training']\n",
    "train_briers.append(train_brier)\n",
    "metrics['Brier Score Training'] = train_briers\n",
    "train_accuracies = metrics['Accuracy Training']\n",
    "train_accuracies.append(train_accuracy)\n",
    "metrics['Accuracy Training'] = train_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the results and adding it to the dictionary\n",
    "results = cross_validate(random_forest,features_preprocessed,target,scoring=['accuracy','neg_brier_score'],\n",
    "                         cv=5,n_jobs=-1)\n",
    "\n",
    "cv_briers = metrics['Mean Brier Score CV']\n",
    "cv_briers.append((-1*results['test_neg_brier_score']).mean())\n",
    "metrics['Mean Brier Score CV'] = cv_briers\n",
    "cv_accuracies = metrics['Mean Accuracy CV']\n",
    "cv_accuracies.append((results['test_accuracy']).mean())\n",
    "metrics['Mean Accuracy CV'] = cv_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model in a pickle file\n",
    "pickle.dump(random_forest,open('/Users/jinalshah/Jinal/Projects/march-madness-mania/models/random_forest_basic.sav','wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "\n",
    "Interesting, Random Forest performed a lot better. Granted, I did add some regularizars such as boostrapping and portion of training set to look at for each tree. Here, I am going to try AdaBoost. I am going to use AdaBoost for Logistic Regression and Decision Trees because I am curious how it will look."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-25 {color: black;background-color: white;}#sk-container-id-25 pre{padding: 0;}#sk-container-id-25 div.sk-toggleable {background-color: white;}#sk-container-id-25 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-25 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-25 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-25 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-25 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-25 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-25 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-25 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-25 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-25 div.sk-item {position: relative;z-index: 1;}#sk-container-id-25 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-25 div.sk-item::before, #sk-container-id-25 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-25 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-25 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-25 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-25 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-25 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-25 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-25 div.sk-label-container {text-align: center;}#sk-container-id-25 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-25 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(estimator=LogisticRegression(max_iter=1000, n_jobs=-1,\n",
       "                                                penalty=None, random_state=42),\n",
       "                   learning_rate=1.5, n_estimators=500, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(estimator=LogisticRegression(max_iter=1000, n_jobs=-1,\n",
       "                                                penalty=None, random_state=42),\n",
       "                   learning_rate=1.5, n_estimators=500, random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, n_jobs=-1, penalty=None, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, n_jobs=-1, penalty=None, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(estimator=LogisticRegression(max_iter=1000, n_jobs=-1,\n",
       "                                                penalty=None, random_state=42),\n",
       "                   learning_rate=1.5, n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model\n",
    "logistic_reg_ada = LogisticRegression(penalty=None,C=1.0,random_state=42,max_iter=1000,n_jobs=-1)\n",
    "adaboost_logistic = AdaBoostClassifier(estimator=logistic_reg_ada,n_estimators=500,learning_rate=1.5,random_state=42)\n",
    "adaboost_logistic.fit(features_preprocessed,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting training scores\n",
    "train_pred = adaboost_logistic.predict(features_preprocessed)\n",
    "train_probs = adaboost_logistic.predict_proba(features_preprocessed)[:,1]\n",
    "\n",
    "# Getting the metrics\n",
    "train_brier = brier_score_loss(target,train_probs)\n",
    "train_accuracy = accuracy_score(target,train_pred)\n",
    "\n",
    "# Adding metrics to the dictionary\n",
    "model_list = metrics['Model']\n",
    "model_list.append('Adaboost - Logistic Regression')\n",
    "metrics['Model'] = model_list\n",
    "train_briers = metrics['Brier Score Training']\n",
    "train_briers.append(train_brier)\n",
    "metrics['Brier Score Training'] = train_briers\n",
    "train_accuracies = metrics['Accuracy Training']\n",
    "train_accuracies.append(train_accuracy)\n",
    "metrics['Accuracy Training'] = train_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the results and adding it to the dictionary\n",
    "results = cross_validate(adaboost_logistic,features_preprocessed,target,scoring=['accuracy','neg_brier_score'],\n",
    "                         cv=5,n_jobs=-1)\n",
    "\n",
    "cv_briers = metrics['Mean Brier Score CV']\n",
    "cv_briers.append((-1*results['test_neg_brier_score']).mean())\n",
    "metrics['Mean Brier Score CV'] = cv_briers\n",
    "cv_accuracies = metrics['Mean Accuracy CV']\n",
    "cv_accuracies.append((results['test_accuracy']).mean())\n",
    "metrics['Mean Accuracy CV'] = cv_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model in a pickle file\n",
    "pickle.dump(adaboost_logistic,open('/Users/jinalshah/Jinal/Projects/march-madness-mania/models/adaboost_logistic.sav','wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost - Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-26 {color: black;background-color: white;}#sk-container-id-26 pre{padding: 0;}#sk-container-id-26 div.sk-toggleable {background-color: white;}#sk-container-id-26 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-26 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-26 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-26 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-26 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-26 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-26 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-26 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-26 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-26 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-26 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-26 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-26 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-26 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-26 div.sk-item {position: relative;z-index: 1;}#sk-container-id-26 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-26 div.sk-item::before, #sk-container-id-26 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-26 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-26 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-26 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-26 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-26 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-26 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-26 div.sk-label-container {text-align: center;}#sk-container-id-26 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-26 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-26\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(random_state=42),\n",
       "                   learning_rate=1.5, n_estimators=500, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(random_state=42),\n",
       "                   learning_rate=1.5, n_estimators=500, random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(estimator=DecisionTreeClassifier(random_state=42),\n",
       "                   learning_rate=1.5, n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model\n",
    "decision_tree_ada = DecisionTreeClassifier(criterion='gini',random_state=42)\n",
    "adaboost_decision_tree = AdaBoostClassifier(estimator=decision_tree_ada,n_estimators=500,learning_rate=1.5,random_state=42)\n",
    "adaboost_decision_tree.fit(features_preprocessed,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting training scores\n",
    "train_pred = adaboost_decision_tree.predict(features_preprocessed)\n",
    "train_probs = adaboost_decision_tree.predict_proba(features_preprocessed)[:,1]\n",
    "\n",
    "# Getting the metrics\n",
    "train_brier = brier_score_loss(target,train_probs)\n",
    "train_accuracy = accuracy_score(target,train_pred)\n",
    "\n",
    "# Adding metrics to the dictionary\n",
    "model_list = metrics['Model']\n",
    "model_list.append('Adaboost - Decision Tree')\n",
    "metrics['Model'] = model_list\n",
    "train_briers = metrics['Brier Score Training']\n",
    "train_briers.append(train_brier)\n",
    "metrics['Brier Score Training'] = train_briers\n",
    "train_accuracies = metrics['Accuracy Training']\n",
    "train_accuracies.append(train_accuracy)\n",
    "metrics['Accuracy Training'] = train_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the results and adding it to the dictionary\n",
    "results = cross_validate(adaboost_decision_tree,features_preprocessed,target,scoring=['accuracy','neg_brier_score'],\n",
    "                         cv=5,n_jobs=-1)\n",
    "\n",
    "cv_briers = metrics['Mean Brier Score CV']\n",
    "cv_briers.append((-1*results['test_neg_brier_score']).mean())\n",
    "metrics['Mean Brier Score CV'] = cv_briers\n",
    "cv_accuracies = metrics['Mean Accuracy CV']\n",
    "cv_accuracies.append((results['test_accuracy']).mean())\n",
    "metrics['Mean Accuracy CV'] = cv_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model in a pickle file\n",
    "pickle.dump(adaboost_decision_tree,open('/Users/jinalshah/Jinal/Projects/march-madness-mania/models/adaboost_dtree.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Brier Score Training</th>\n",
       "      <th>Mean Brier Score CV</th>\n",
       "      <th>Accuracy Training</th>\n",
       "      <th>Mean Accuracy CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy Classifier</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.51681</td>\n",
       "      <td>0.50124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression - No Regularization</td>\n",
       "      <td>0.16506</td>\n",
       "      <td>0.22291</td>\n",
       "      <td>0.76526</td>\n",
       "      <td>0.66005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree - UnRegularized</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.41093</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.58907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest - Basic</td>\n",
       "      <td>0.05107</td>\n",
       "      <td>0.20731</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.67310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adaboost - Logistic Regression</td>\n",
       "      <td>0.24962</td>\n",
       "      <td>0.24968</td>\n",
       "      <td>0.74533</td>\n",
       "      <td>0.66504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adaboost - Decision Tree</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.42714</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.57286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Model  Brier Score Training  \\\n",
       "0                         Dummy Classifier               0.25000   \n",
       "1  Logistic Regression - No Regularization               0.16506   \n",
       "2            Decision Tree - UnRegularized               0.00000   \n",
       "3                    Random Forest - Basic               0.05107   \n",
       "4           Adaboost - Logistic Regression               0.24962   \n",
       "5                 Adaboost - Decision Tree               0.00000   \n",
       "\n",
       "   Mean Brier Score CV  Accuracy Training  Mean Accuracy CV  \n",
       "0              0.25000            0.51681           0.50124  \n",
       "1              0.22291            0.76526           0.66005  \n",
       "2              0.41093            1.00000           0.58907  \n",
       "3              0.20731            1.00000           0.67310  \n",
       "4              0.24968            0.74533           0.66504  \n",
       "5              0.42714            1.00000           0.57286  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting metrics into a dataframe\n",
    "pd.options.display.float_format = '{:.5f}'.format # Making sure it doesn't display in scientific notation\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "march-madness-mania",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd35a392fde1dc673d11d63530ba2243a9ec2532d473e3b8a20605e035add6e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
